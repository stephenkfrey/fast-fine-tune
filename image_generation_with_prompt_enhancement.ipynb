{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftm_id = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Generate images from results --\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-37KR1qzwE8sS5pwTqFlYtiPS at 0x7ff38a655df0> JSON: {\n",
       "  \"created_at\": 1673608342,\n",
       "  \"events\": [\n",
       "    {\n",
       "      \"created_at\": 1673608342,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-37KR1qzwE8sS5pwTqFlYtiPS\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673614550,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune costs $0.93\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673614551,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune enqueued\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617371,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 31\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617440,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 30\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617479,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 29\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617562,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 28\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617586,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 27\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617666,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 26\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617713,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 25\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617723,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 24\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617817,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 23\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617877,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 22\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673617892,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 21\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618152,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 20\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618196,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 19\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618365,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 18\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618369,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 17\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618494,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 16\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618505,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 15\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618551,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 14\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618699,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 13\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618701,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 12\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618868,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 11\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673618888,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 10\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673619193,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 9\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673619676,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 8\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673619895,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 7\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620009,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 6\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620177,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 5\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620213,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620301,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 3\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620339,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620441,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620487,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620490,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune started\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620599,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 1/2\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620625,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 2/2\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620657,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded model: davinci:ft-sandbox:ml-gptchat-qa-2023-01-13-14-37-37\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620659,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded result file: file-cddzlZ3kfjnVTNJtanGMiEGk\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1673620659,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune succeeded\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    }\n",
       "  ],\n",
       "  \"fine_tuned_model\": \"davinci:ft-sandbox:ml-gptchat-qa-2023-01-13-14-37-37\",\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": 1,\n",
       "    \"learning_rate_multiplier\": 0.02,\n",
       "    \"n_epochs\": 2,\n",
       "    \"prompt_loss_weight\": 0.01\n",
       "  },\n",
       "  \"id\": \"ft-37KR1qzwE8sS5pwTqFlYtiPS\",\n",
       "  \"model\": \"davinci\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-5RSpJP9M5vC6iGBmX0vRfiMp\",\n",
       "  \"result_files\": [\n",
       "    {\n",
       "      \"bytes\": 6090,\n",
       "      \"created_at\": 1673620658,\n",
       "      \"filename\": \"compiled_results.csv\",\n",
       "      \"id\": \"file-cddzlZ3kfjnVTNJtanGMiEGk\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 65711,\n",
       "      \"created_at\": 1673608341,\n",
       "      \"filename\": \"file\",\n",
       "      \"id\": \"file-2v0x76EyT1qtw68XUUqHErzZ\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1673620659,\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myftm = get_ftm_from_id(ftm_id)\n",
    "myftm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model info as JSON \n",
    "import json\n",
    "with open(f\"models/{this_model_name}-{ftm_id}.json\", 'w') as f:\n",
    "    json.dump(myftm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the .env file is loaded so it loads the API key as an environment variable \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# assert there is a REPLICATE_API_TOKEN\n",
    "import os\n",
    "assert os.getenv('REPLICATE_API_TOKEN') is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "model = replicate.models.get(\"stability-ai/stable-diffusion\")\n",
    "version = model.versions.get(\"6359a0cab3ca6e4d3320c33d79096161208e9024d174b2311e5a21b6c7e1131c\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST \n",
    "# # display the image at the URL in the output\n",
    "# output = version.predict(prompt=\"a photo of an astronaut riding a horse on mars\")\n",
    "# from IPython.display import Image\n",
    "# Image(url=output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_replicate_image(prompt):\n",
    "    return version.predict(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('prepend_enhancement_prompt.txt', 'r') as f:\n",
    "    prepended_image_caption_enhancement_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests \n",
    "\n",
    "def get_image_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    # set the img width to 200 px \n",
    "    basewidth = 200\n",
    "    wpercent = (basewidth/float(img.size[0]))\n",
    "    hsize = int((float(img.size[1])*float(wpercent)))\n",
    "    \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# For each phrase in the test_prompts_path, \n",
    "# then use the ftm to get the expanded phrase \n",
    "# get use replicate to get the image for the phrase, \n",
    "# then use replicate to get the image for the expanded phrase \n",
    "# \"\"\"\n",
    "\n",
    "# import replicate\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# original_prompts_imgs = {}\n",
    "# expanded_prompts_imgs = {}\n",
    "\n",
    "# with open (test_prompts_path) as f:\n",
    "#     prompts = f.readlines()\n",
    "\n",
    "#     for prompt in prompts: \n",
    "        \n",
    "#         original_prompts_imgs[prompt]=get_replicate_image(prompt)\n",
    "\n",
    "#         expanded_prompt = get_gpt_response_text(prepended_image_caption_enhancement_prompt+prompt, ftm_name, printit=False)\n",
    "#         #remove the first instance of the word \"Expanded: \" from the beginning of the expanded prompt\n",
    "#         expanded_prompt = expanded_prompt.replace(\"Expanded: \", \"\", 1)\n",
    "#         expanded_prompts_imgs[expanded_prompt]=get_replicate_image(expanded_prompt)\n",
    "\n",
    "#         print(f\"== Original prompt: {prompt}\")\n",
    "#         print(f\"== Expanded prompt: {expanded_prompt}\")\n",
    "\n",
    "#         # print(f\"original prompt image: {original_prompts_imgs[-1]}\")\n",
    "#         # print(f\"expanded prompt image: {expanded_prompts_imgs[-1]}\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prompt: What is the difference between a CNN and a DNN? \n",
      "\n",
      "ftm_name davinci:ft-sandbox:ml-gptchat-qa-2023-01-13-14-37-37\n",
      "Expanded prompt: Expanded: A CNN is a Convolutional Neural Network, and a DNN is a Deep Neural Network, they are used for image recognition and classification, with a CNN being more accurate for classification, and a DNN being more accurate for image recognition. \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Expanded: \n",
      "\n",
      "Original: \n",
      "Exp\n"
     ]
    }
   ],
   "source": [
    "import replicate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "NOIMAGE = False\n",
    "\n",
    "prompts_images_df = pd.DataFrame(columns=['original_prompt', 'original_image', 'expanded_prompt', 'image'])\n",
    "\n",
    "with open (test_prompts_path) as f: \n",
    "    prompts = f.readlines()\n",
    "    for prompt in prompts: \n",
    "        print (f\"Original prompt: {prompt}\")\n",
    "\n",
    "        ##### Get expanded prompt from GPT \n",
    "        print('ftm_name', ftm_name)\n",
    "        expanded_prompt = get_gpt_response_text(prepended_image_caption_enhancement_prompt+prompt, ftm_name, printit=False)\n",
    "        print (f\"Expanded prompt: {expanded_prompt}\")\n",
    "\n",
    "        ### for testing \n",
    "        if NOIMAGE: \n",
    "            continue\n",
    "\n",
    "\n",
    "        ##### Get image for original prompt from Replicate \n",
    "        original_image = get_replicate_image(prompt)\n",
    "        # display it \n",
    "        i = get_image_from_url(original_image[0])\n",
    "        i = i.resize((200,200), Image.ANTIALIAS)\n",
    "        display(i)\n",
    "\n",
    "        \n",
    "        #remove the first instance of the word \"Expanded: \" from the beginning of the expanded prompt\n",
    "        expanded_prompt = expanded_prompt.replace(\"Expanded: \", \"\", 1)\n",
    "        print (f\"Expanded prompt: {expanded_prompt}\")\n",
    "\n",
    "        ##### Get image for expanded prompt from Replicate\n",
    "        expanded_image = get_replicate_image(expanded_prompt)\n",
    "        # display it\n",
    "        i = get_image_from_url(original_image[0])\n",
    "        i = i.resize((200,200), Image.ANTIALIAS)\n",
    "        display(i)\n",
    "\n",
    "        # append all to the dataframe\n",
    "        prompts_images_df = prompts_images_df.append(\n",
    "            {'original_prompt': prompt, 'original_image': original_image, \n",
    "            'expanded_prompt': expanded_prompt, 'image': expanded_image}, \n",
    "            ignore_index=True)\n",
    "\n",
    "\n",
    "# save the df to a csv\n",
    "prompts_images_df.to_csv('prompts_images_df.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "thang = get_replicate_image(\"yoyoyoyo\")\n",
    "# display it \n",
    "print(type(thang))\n",
    "print(type(thang[0]))\n",
    "print(type(Image))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make a a grid with two columns, where each row has the original prompt above the original image, and the expanded prompt above the expanded image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def quick_plot_grid_results(): \n",
    "\n",
    "    # get the number of rows and columns \n",
    "    nrows = len(prompts_images_df)\n",
    "    ncols = 2\n",
    "\n",
    "    # create a figure and axes\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(10, 10))\n",
    "\n",
    "    # set the spacing between subplots\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "    # set the title of the figure\n",
    "    fig.suptitle('Original and Expanded Prompts and Images', fontsize=16)\n",
    "\n",
    "    # iterate through the rows of the dataframe\n",
    "    for i, row in prompts_images_df.iterrows():\n",
    "\n",
    "        # get the original prompt and image\n",
    "        # word wrap the text of the prompt inside of the column \n",
    "\n",
    "        original_prompt = row['original_prompt']\n",
    "        original_image = row['original_imgage']\n",
    "\n",
    "        #word warp \n",
    "        original_prompt = '\\n'.join(wrap(original_prompt, 50))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # get the expanded prompt and image\n",
    "        expanded_prompt = row['expanded_prompt']\n",
    "        expanded_image = row['image']\n",
    "\n",
    "        # word wrap the text of the prompt inside of the column\n",
    "        expanded_prompt = '\\n'.join(wrap(expanded_prompt, 50))\n",
    "\n",
    "        # display the original prompt and image\n",
    "        axs[i, 0].set_title(original_prompt)\n",
    "        axs[i, 0].imshow(mpimg.imread(original_image[0]))\n",
    "\n",
    "        # display the expanded prompt and image\n",
    "        axs[i, 1].set_title(expanded_prompt)\n",
    "        axs[i, 1].imshow(mpimg.imread(expanded_image[0]))\n",
    "\n",
    "    # hide the x and y ticks\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # display the figure\n",
    "    plt.show()\n",
    "\n",
    "# quick_plot_grid_results()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the df and display each pair of original prompt, original image, expanded prompt, expanded image\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "save_image_dir = \"images\"\n",
    "\n",
    "\n",
    "for index, row in prompts_images_df.iterrows():\n",
    "    print (f\"Original Prompt: {row['original_prompt']}\")\n",
    "\n",
    "    # download hte image from a url and save it \n",
    "\n",
    "    # get the url of the image\n",
    "    original_url = row['original_imgage'][0]\n",
    "\n",
    "    # download the image from the url \n",
    "    \n",
    "\n",
    "    img_data = requests.get(url).content\n",
    "    filename=f\"{index}_original.png\"\n",
    "    filepath = os.path.join(save_image_dir, filename)\n",
    "\n",
    "    # save as a PIL image \n",
    "\n",
    "\n",
    "    print(type(row['original_imgage']))\n",
    "    print(row['original_imgage'][0])\n",
    "    i = Image(url=row['original_imgage'][0])\n",
    "    print (type(i))\n",
    "    i.save(filename=filepath)\n",
    "\n",
    "    # save the image to a file\n",
    "\n",
    "    # os join save_image_dir and the filename\n",
    "    expanded_url = row['image'][0]\n",
    "    img_data = requests.get(url).content\n",
    "    filename=f\"{index}_expanded.png\"\n",
    "    filepath = os.path.join(save_image_dir, filename)\n",
    "\n",
    "    i = Image(url=row['image'][0])\n",
    "    i.save(filename=filepath)\n",
    "\n",
    "    # with open(filepath, 'wb') as handler:\n",
    "    #     handler.write(img_data)\n",
    "        # why does this throw an error?\n",
    "        # i.save(filename=filepath)\n",
    "\n",
    "    # # save the Image object as an image file\n",
    "    # i.save(filename=filepath)\n",
    "\n",
    "    # i.width = 400\n",
    "    # display(i)\n",
    "\n",
    "    print (f\"Expanded Prompt: {row['expanded_prompt']}\")\n",
    "    # # save the image to a file\n",
    "    # filename=f\"exp_prompt{index}_{row['expanded_prompt']}.png\"\n",
    "    # filepath = os.path.join(save_image_dir, filename)\n",
    "    # # i.save(filename=filepath)\n",
    "\n",
    "\n",
    "    # i = Image(url=row['image'][0])\n",
    "    # i.width = 400\n",
    "    # display(i)\n",
    "\n",
    "    print (\"============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both dicts to a csv \n",
    "import csv\n",
    "\n",
    "def save_dict_to_csv(d, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        w = csv.DictWriter(f, d.keys())\n",
    "        w.writeheader()\n",
    "        w.writerow(d)\n",
    "\n",
    "# get datetimestamp to the minute\n",
    "# import datetime\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "# save_dict_to_csv(original_prompts_imgs, f\"outputs/original_prompts_imgs{now}.csv\")\n",
    "# save_dict_to_csv(expanded_prompts_imgs, f\"outputs/expanded_prompts_imgs{now}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:11:24) \n[Clang 11.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bf0429cbc4594f61fb4a70c70f57b312684948f13d28d948c6a6ee3f95ed4f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
