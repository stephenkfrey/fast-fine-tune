{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Fine-tuning API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# set the api key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Notes on formatting for GPT fine-tuning ####################\n",
    "\n",
    "# - Based on your file extension, your file is formatted as a CSV file\n",
    "# - Your file contains 56 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
    "# - Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
    "# - All completions end with suffix ` `\n",
    "#   WARNING: Some of your completions contain the suffix ` ` more than once. We suggest that you review your completions and add a unique ending\n",
    "# - The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
    "\n",
    "# add a space to the end of each prompt\n",
    "# Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is \\n\\n###\\n\\n. The separator should not appear elsewhere in any prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Load raw CSV files of prompt-completion pairs --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT Chat\n",
    "pc_csv_IN_path =\"data/gptchatqadata/gpt-qa-df.csv\"\n",
    "curr_suffix_name = \"gpt-ml-qa-pairs-C\"\n",
    "\n",
    "assert os.path.exists(pc_csv_IN_path), \"File does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FastAI Q&A pairs \n",
    "pc_csv_IN_path =\"data/fastaiqadata/fastai-qa-cleaned.csv\"\n",
    "curr_suffix_name = \"fastai-ft\"\n",
    "\n",
    "assert os.path.exists(pc_csv_IN_path), \"File does not exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Format raw CSV --> formatted CSV --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#####\n",
      "Raw CSV -> Formatted CSV conversion complete\n",
      "#####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# INPUTS: \n",
    "# - csv: a csv with headers 'prompt' and 'completion'\n",
    "\n",
    "# PROCESSING: \n",
    "# - add a space to the end of each prompt\n",
    "# - add a \\n\\n###\\n\\n to the end of each prompt\n",
    "# - add a space to the beginning of each completion\n",
    "# - add a \\n\\n<+++>\\n\\n to the end of each completion\n",
    "\n",
    "# saves to df\n",
    "\n",
    "# OUTPUTS:\n",
    "# - csv: a cleaned, formatted csv ready for fine-tuning \n",
    "\n",
    "def format_csv_for_ft(qa_csv_path):\n",
    "    #### Check formatting on CSV \n",
    "    assert qa_csv_path[-4:] == '.csv', \"input path does not end with '.csv'\"\n",
    "    # - headers are 'prompt' and 'completion'\n",
    "    assert pd.read_csv(qa_csv_path, nrows=0).columns.tolist() == ['prompt', 'completion'], \"file headers are not 'prompt' and 'completion'\"\n",
    "\n",
    "    gpt_formatted_df = pd.read_csv(qa_csv_path)\n",
    "    # print(gpt_loaded_df.head()) # double check input \n",
    "\n",
    "    #### Format for fine-tuning \n",
    "    # 1) Completions: start with a space ' ', end with a seperator '\\n+END+\\n'\n",
    "    # Each completion should start with a whitespace due to our tokenization, which tokenizes most words with a preceding whitespace.\n",
    "    # Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be \\n, ###, or any other token that does not appear in any completion.\n",
    "    gpt_formatted_df['completion'] = gpt_formatted_df['completion'].apply(lambda x: ' ' + x + ' END')\n",
    "    # 2) add a separater to the end of each prompt \n",
    "    gpt_formatted_df['prompt'] = gpt_formatted_df['prompt'].apply(lambda x: x + '\\n\\n###\\n\\n')\n",
    "\n",
    "    #### Save to csv \n",
    "    qa_csv_OUT_path=os.path.join(pc_csv_IN_path[:-4]+\"-MANUAL-formatted.csv\")\n",
    "    gpt_formatted_df.to_csv(qa_csv_OUT_path, index=False)\n",
    "    return qa_csv_OUT_path\n",
    "\n",
    "formatted_pc_csv_path = format_csv_for_ft(pc_csv_IN_path)\n",
    "\n",
    "print(\"\\n#####\\nRaw CSV -> Formatted CSV conversion complete\\n#####\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE splitting train and valid set; not used right now \n",
    "\n",
    "# def split_df_train_test(df, train_frac=0.8):\n",
    "#     # split the df into train and test\n",
    "#     train_df = df.sample(frac=train_frac, random_state=42)\n",
    "#     test_df = df.drop(train_df.index)\n",
    "\n",
    "#     return train_df, test_df\n",
    "\n",
    "######\n",
    "# ## # get train and test df from the previous 'formatted_qa_df'\n",
    "# qa_train_df, qa_test_df = split_df_train_test(formatted_qa_df)\n",
    "\n",
    "# #create paths to save \n",
    "# qa_TEST_OUT_path = f\"{qa_csv_IN_path[:-4]}-TRAIN.csv\"\n",
    "# qa_TRAIN_OUT_path = f\"{qa_csv_IN_path[:-4]}-TEST.csv\"\n",
    "\n",
    "# # # save the train and test dfs to csv \n",
    "# qa_train_df.to_csv(qa_TEST_OUT_path, index=False)\n",
    "# qa_test_df.to_csv(qa_TRAIN_OUT_path, index=False)\n",
    "\n",
    "# print ('train/test shapes: ', qa_train_df.shape, qa_test_df.shape)\n",
    "# print ('train/test heads: \\n\\n', qa_train_df.head(),qa_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV -> JSONL, using the OpenAI CLI tool\n",
    "\n",
    "*Typically, we call the following in terminal to convert the file:*\n",
    "\n",
    "`openai tools fine_tunes.prepare_data -f <LOCAL_FILE>`\n",
    "\n",
    "The following section automates this with a bash script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TODO \n",
    "Eventually, run a bash script that gets the output from terminal and displays to user \n",
    "to make choices about data formatting\n",
    "for now lets just do it manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_conversion_sh_script_path = './scripts/csv2jsonl_openai.sh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assure permissions for the bash script and file \n",
    "! chmod a+x {jsonl_conversion_sh_script_path}\n",
    "! chmod a+x {formatted_pc_csv_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 223 prompt-completion pairs\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix ` END\\n`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `data/fastaiqadata/fastai-qa-cleaned-MANUAL-formatted_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"data/fastaiqadata/fastai-qa-cleaned-MANUAL-formatted_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 5.51 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Done!\n",
      "\n",
      "./scripts/csv2jsonl_openai.sh: line 18: syntax error near unexpected token `done'\n",
      "./scripts/csv2jsonl_openai.sh: line 18: `done'\n",
      "\n",
      "data/fastaiqadata/fastai-qa-cleaned-MANUAL-formatted_prepared.jsonl\n",
      "\n",
      "#####\n",
      "CSV -> JSONL conversion complete\n",
      "#####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Run the OpenAI CLI tool to format the CSV to JSONL \n",
    "import subprocess\n",
    "# you need to add './' before the filename for bash to recognize it \n",
    "\n",
    "assert os.path.exists(formatted_pc_csv_path), \"file does not exist\"\n",
    "assert os.path.exists(jsonl_conversion_sh_script_path), \"sh file does not exist\"\n",
    "\n",
    "# Call the bash script to format the CSV to JSONL using the OpenAI CLI tool \n",
    "process = subprocess.Popen([jsonl_conversion_sh_script_path, formatted_pc_csv_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "if process is not None:\n",
    "    stdout, stderr = process.communicate()\n",
    "    print(stdout.decode('utf-8'))\n",
    "    print(stderr.decode('utf-8'))\n",
    "    \n",
    "    \n",
    "# get the new JSONL filename \n",
    "formatted_pc_jsonl_path = formatted_pc_csv_path[:-4] + '_prepared.jsonl'\n",
    "assert (os.path.exists(formatted_pc_jsonl_path)), \"JSONL file does not exist\"\n",
    "print(formatted_pc_jsonl_path)\n",
    "print(\"\\n#####\\nCSV -> JSONL conversion complete\\n#####\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to format the API call to the fine tuned model \n",
    "\n",
    "### format the prompt from the user before sending it \n",
    "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string \n",
    "\n",
    "`\\n\\n###\\n\\n` \n",
    "\n",
    "for the model to start generating completions, rather than continuing with the prompt. \n",
    "\n",
    "### param in API call for stop sequence \n",
    "Make sure to include \n",
    "\n",
    "`stop=[\" \\n<+++>\\n\"]` \n",
    "\n",
    "so that the generated texts ends at the expected place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### an example call to create a ft model in terminal: \n",
    "\n",
    "openai api fine_tunes.create \\\n",
    "-t gpt-qa-train_prepared.jsonl \\\n",
    "-v gpt-qa-valid_prepared.jsonl \\\n",
    "-m \"davinci\" \\\n",
    "--suffix \"gpt-ml-qa-pairs-A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Functions to create a fine-tuned model from the JSONL file --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# HELPER FUNCTIONS\n",
    "#####################\n",
    "\n",
    "# FUNCTION \n",
    "# upload_file_openai\n",
    "# - takes in a jsonl formatted dataset (just training set for now for simplicity)\n",
    "# - eventually could abstract to general file upload but not needed for now\n",
    "def upload_jsonl_ft_to_openai(filename): \n",
    "    # assert the filetype is jsonl \n",
    "    ext = os.path.splitext(filename)[-1].lower()\n",
    "    print ('ext:', ext)\n",
    "    assert ext== '.jsonl', \"filetype must be jsonl\"\n",
    "    r = openai.File.create(\n",
    "        file=open(filename, \"rb\"),\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# FUNCTION \n",
    "# create_finetuned_model\n",
    "\n",
    "# INPUTS: \n",
    "# - train_file_id: a csv with headers 'prompt' and 'completion'\n",
    "# - model type\n",
    "# - hyperparameters\n",
    "\n",
    "# OUTPUTS:\n",
    "# finetuned_model_response: a response object including the finetuned model id\n",
    "\n",
    "# @TODO add the ability to turn on and off test-train splitting \n",
    "\n",
    "def create_finetuned_model(train_file_id, valid_file_id='', model=\"davinci-003\", learning_rate_multiplier='', n_epochs='', suffix=''):\n",
    "\n",
    "    #####################\n",
    "    # create the request to build the finetuned model \n",
    "    try: \n",
    "        finetuned_model_response = openai.FineTune.create(\n",
    "            training_file=train_file_id,\n",
    "            # validation_file=valid_file_id, # ignore valid file for now\n",
    "            model=model,\n",
    "            learning_rate_multiplier=learning_rate_multiplier,\n",
    "            n_epochs=n_epochs,\n",
    "            suffix=suffix,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print (\"Error creating finetuned model: \", e)\n",
    "        return None\n",
    "    return finetuned_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE \n",
    "# this is the old way using a train/valid set \n",
    "\n",
    "# _train_file_id = upload_file_openai('gpt-qa-train-formatted_prepared.jsonl')['id']\n",
    "# _valid_file_id = upload_file_openai('gpt-qa-valid-formatted_prepared.jsonl')['id']\n",
    "\n",
    "# ftm = create_finetuned_model(\n",
    "#     train_file_id=_train_file_id,\n",
    "#     valid_file_id=_valid_file_id,\n",
    "#     model=\"davinci\",\n",
    "#     learning_rate_multiplier=0.05,\n",
    "#     n_epochs=1,\n",
    "#     suffix=suffix_name,\n",
    "# )\n",
    "\n",
    "# ftm_id = ftm['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the finetuned model id to the list.csv file, along with the datetime\n",
    "\n",
    "def log_finetuned_model_id(ftm_id, model_name, learning_rate_multiplier, n_epochs, suffix, log_file_path):\n",
    "    # get the current datetime \n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    # create the row to append \n",
    "    row = f\"{dt_string},{ftm_id},{model_name},{learning_rate_multiplier},{n_epochs},{suffix}\" \n",
    "    # append the row to the log file\n",
    "    with open(log_file_path, 'a') as f:\n",
    "        f.write(row + '\\n')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# FUNCTION: file_to_finetuned_model\n",
    "\n",
    "\n",
    "\"\"\"\"\n",
    "file_to_finetuned_model_wrapper\n",
    "\n",
    "Inputs: \n",
    "    filename: \n",
    "        - filename path of a csv file to be uploaded to openai\n",
    "        - must be formatted as a csv with headers 'prompt' and 'completion' - see the functions above to do that \n",
    "            eg \"/data/my-prompt-completion-pairs-list.csv\"\n",
    "\n",
    "    model: string, name of the model to be finetuned \n",
    "            eg \"davinci-003\"\n",
    "    \n",
    "    learning_rate_multiplier: float, learning rate multiplier for the finetuned model \n",
    "            eg \"0.05\", typically 0.05 - 0.2\n",
    "    \n",
    "    n_epochs: int, number of epochs for the finetuned model \n",
    "            eg \"1\", typically 1 - 3\n",
    "    \n",
    "    suffix: string, suffix to be added to the finetuned model \n",
    "            eg \"my-finetuned-model\"\n",
    "\n",
    "Outputs: \n",
    "    finetuned_model_response: the response of the OpenAI API call to create the finetuned model\n",
    "        - a dictionary with the finetuned model id, hyperparameters, model name, etc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "def file_to_finetuned_model_wrapper(train_file, valid_file='', model=\"davinci\", learning_rate_multiplier=0.1, n_epochs=4, suffix=''):\n",
    "    # upload files to openai\n",
    "    if train_file:\n",
    "        assert(train_file.endswith('.jsonl')), \"train_file must be a .jsonl file\"\n",
    "        _train_file_id = upload_jsonl_ft_to_openai(train_file)['id']\n",
    "        print ('Successfully uploaded train JSONL file. train_file_id:', _train_file_id)\n",
    "    else:\n",
    "        FileNotFoundError('Must include a train_file')\n",
    "\n",
    "    if valid_file != '':\n",
    "        assert(valid_file.endswith('.jsonl')), \"valid_file must be a .jsonl file\"\n",
    "        _valid_file_id = upload_jsonl_ft_to_openai(valid_file)['id']\n",
    "    else: \n",
    "        _valid_file_id = ''\n",
    "\n",
    "    # ensure suffix is within the required length; if not then truncate\n",
    "    if len(suffix) > 40:\n",
    "        suffix = suffix[:40]\n",
    "        print('Suffix longer than required 40-character length; truncating to 40 characters: ', suffix)\n",
    "    \n",
    "    \n",
    "    # create a finetuned model\n",
    "    finetuned_model_response = create_finetuned_model(\n",
    "        train_file_id=_train_file_id,\n",
    "        # valid_file_id=_valid_file_id,\n",
    "        model=model,\n",
    "        learning_rate_multiplier=learning_rate_multiplier,\n",
    "        n_epochs=n_epochs,\n",
    "        suffix=suffix,\n",
    "    )\n",
    "\n",
    "    return finetuned_model_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Create a ftm from the JSONL file --- \n",
    "The magic is here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftm = file_to_finetuned_model_wrapper(\n",
    "    train_file=formatted_pc_jsonl_path, #from the previous step \n",
    "    suffix=curr_suffix_name # declared at the beginning of the ntoebook \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log each element of the json response as a column in a csv file\n",
    "from datetime import datetime\n",
    "\n",
    "def log_ftm(ftm):\n",
    "    \"\"\"\n",
    "    # Checks if the ftm id is already in the log file. If not, then adds to log file. \n",
    "    # INPUTS: ftm - the json response from the OpenAI API call to create a finetuned model\n",
    "    # OUTPUTS: True/False\n",
    "    \"\"\"\n",
    "    log_file_path = 'outputs/finetuned-models-log.csv'\n",
    "\n",
    "    if not os.path.exists(log_file_path):\n",
    "        with open(log_file_path, 'w') as f:\n",
    "            f.write('datetime,created_at,ftm_id, status\\n')\n",
    "\n",
    "    # check if the ftm id already exists in the csv \n",
    "    pattern = ftm['id']\n",
    "    with open(log_file_path, 'r') as csvfile:\n",
    "        if any(map(lambda x: pattern == x.rstrip(), csvfile)): # iterates through text looking for match\n",
    "            print (\"Finetuned model id already exists in log file\")\n",
    "            return False\n",
    "        else:\n",
    "            with open(log_file_path, 'a') as f:\n",
    "                f.write(f\"{datetime.now()}, {ftm['created_at']},{ftm['id']}, {ftm['status']}\\n\")\n",
    "            return True\n",
    "    \n",
    "\n",
    "log_ftm(ftm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print *initial* profile of ftm. \n",
    "Note that it's still being trained, so \n",
    "\n",
    "Name: none\n",
    "\n",
    "Status: pending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftm_id = ftm['id']\n",
    "\n",
    "print(f\"\\n###\\nCreated fine-tuned model {ftm_id}\\n###\\n\")\n",
    "print ('ftm_id: ', ftm_id)\n",
    "print ('status: ', ftm['status'])\n",
    "print ('ftm: ', ftm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Test with FastAI Question-Answer Pairs data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftm_fastai = file_to_finetuned_model_wrapper(\n",
    "    train_file='data/fastaiqadata/fastai-qa-cleaned-formatted-CSV-FIRST_prepared.jsonl', # NEEDS UPDATING \n",
    "    suffix='fastai-qa-cleaned-formatted-CSV-FIRST_prepared',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('id ', ftm_fastai['id'])\n",
    "print('name ',ftm_fastai['fine_tuned_model'])\n",
    "print('status ', ftm_fastai['status'])\n",
    "print (display_unix_time(ftm['created_at']))\n",
    "print ('ftm: ', ftm_fastai)\n",
    "\n",
    "####\n",
    "whatsup = openai.FineTune.retrieve(ftm_fastai['id'])\n",
    "whatsup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Test with GPT Chat log data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST GPT CHAT DATA \n",
    "# test the file_to_finetuned_model function\n",
    "\n",
    "banana_file = \"data/gptchatqadata/gpt-qa-train-formatted_prepared.jsonl\"\n",
    "banana_suffix=\"qa-train-iterate\"\n",
    "\n",
    "ftm_gptchat = file_to_finetuned_model_wrapper(\n",
    "    train_file=banana_file,\n",
    "    suffix=banana_suffix + \"-z\"\n",
    ")\n",
    "\n",
    "print('id: ',ftm_gptchat['id'])\n",
    "print('name: ',ftm_gptchat['fine_tuned_model'])\n",
    "\n",
    "# ftm is only available after the model has been created!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPERS \n",
    "\n",
    "def get_ftmodel_name_from_id(id):\n",
    "    ftmodel = openai.FineTune.retrieve(id)\n",
    "    return ftmodel['fine_tuned_model']\n",
    "\n",
    "def get_ftmodel_id_from_name(name):\n",
    "    all_ft_models = openai.FineTune.list()['data']\n",
    "    for ftmodel in all_ft_models:\n",
    "        if name in ftmodel['fine_tuned_model']:\n",
    "            return ftmodel['id']\n",
    "    return None\n",
    "\n",
    "def get_ftm_from_id(id):\n",
    "    return openai.FineTune.retrieve(id)\n",
    "\n",
    "print(get_ftmodel_name_from_id(\"ft-xXiSGiL0RrMUpKikJw09T1up\"))\n",
    "print(get_ftmodel_id_from_name(\"davinci:ft-sandbox:qa-train-iterate-lrm-0-1-epoch-1-2022-11-20-12-50-36\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FTM AWAIT READY \n",
    "\n",
    "# the finetuned model needs to finish training before we can use it\n",
    "# so let's track its status and only make calls when its' ready \n",
    "# we can use the finetuned model id to check its status\n",
    "\n",
    "import time\n",
    "\n",
    "def get_finetuned_model_status(finetuned_model_id):\n",
    "    response = openai.FineTune.retrieve(id=finetuned_model_id)\n",
    "    return response['status']\n",
    "\n",
    "#####\n",
    "# FUNCTION: await_ft_ready\n",
    "# INPUT: finetuned_model_id, seconds_of_patience\n",
    "# prints every check_every_n_seconds seconds the status of the mdoel \n",
    "# times out after seconds_of_patience seconds\n",
    "# OUTPUT: True if finetuned model is ready, False if finetuned model is not ready\n",
    "\n",
    "def await_ft_ready(finetuned_model_id, seconds_of_patience=400):\n",
    "\n",
    "    check_every_n_seconds = 10\n",
    "    # round down \n",
    "    num_checkins = seconds_of_patience//check_every_n_seconds # number of times to check the status of the finetuned model\n",
    "    print(f\"###\\nWaiting for {finetuned_model_id} to train.\\n###\\n\")\n",
    "\n",
    "    finetuned_model_status = None \n",
    "    counter = 0\n",
    "\n",
    "    while True:\n",
    "        status = get_finetuned_model_status(finetuned_model_id)\n",
    "        if status == 'succeeded':\n",
    "            print(f\"###\\n{finetuned_model_id} is ready!\\n###\\n\")\n",
    "            print (openai.FineTune.retrieve(id=finetuned_model_id))\n",
    "            return True\n",
    "        else:\n",
    "            counter +=1\n",
    "            print (f\"{finetuned_model_id} status: {status}\")\n",
    "            print(f\"{finetuned_model_id} finetuned model is still training. {counter*check_every_n_seconds} seconds so far.\")\n",
    "            print ('counter',counter)\n",
    "            \n",
    "            if counter % 10 == 0: #arbitrary every N check ins, print update \n",
    "                print(f\"{finetuned_model_id} has trained for at least {counter*check_every_n_seconds} seconds so far. Status: {status}\")\n",
    "            if counter > num_checkins: \n",
    "                # print that the current timed out\n",
    "                print(f\"{finetuned_model_id} finetuned model has taken longer than {seconds_of_patience} to train, since we started checking in on its status. Calling exceeds patience variable. Exiting await-train loop.\")\n",
    "                print (openai.FineTune.retrieve(id=finetuned_model_id))\n",
    "                return False\n",
    "            time.sleep(check_every_n_seconds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert unix time to human readable time\n",
    "import datetime\n",
    "def display_unix_time(unix_time):\n",
    "    return datetime.datetime.fromtimestamp(unix_time).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ftm_trained_id ='ft-xXiSGiL0RrMUpKikJw09T1up'\n",
    "print (display_unix_time(ftm['created_at']))\n",
    "await_ft_ready(ftm_trained_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_latest_ftm(_ftm_id):\n",
    "    ftm = openai.FineTune.retrieve(id=_ftm_id)\n",
    "    print (f\"###\\nid: {ftm['id']}\\nname:{ftm['fine_tuned_model']} \\ncreated at: {display_unix_time(ftm['created_at'])} \\nstatus: {ftm['status']}\\n###\\n\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~ Flip this on if you want it to wait on the actual ftm we just loaded ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latest_ftm(ftm_fastai['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await_ft_ready(ftm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next to add: database\n",
    "\n",
    "- add ftm to a local sql database upon creation \n",
    "- cron job to check every 5 mins if status updated and is ready\n",
    "- if so then update the status in the db, and also send a notification somehow? maybe just have the db loaded up in a prisma studio in the browser \n",
    "- also all of this just feeds into the product, it's one of two training pipelines \n",
    "- i kinda want to see about the other one now too \n",
    "- but it's late and time to sleep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We attach a result file to each job once it has been completed. This results file ID will be listed when you retrieve a fine-tune, and also when you look at the events on a fine-tune. You can download these files.\n",
    "\n",
    "The _results.csv file contains a row for each training step, where a step refers to one forward and backward pass on a batch of data. \n",
    "\n",
    "openai api fine_tunes.results -i <YOUR_FINE_TUNE_JOB_ID>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminal outputs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(ml) SF-mbp:gpt-fine-tuning stephen$ openai api fine_tunes.create \\\n",
    "> -t gpt-qa-train_prepared.jsonl \\\n",
    "> -v gpt-qa-valid_prepared.jsonl\n",
    "-m \"davinci\" \\\n",
    "--suffix \"gpt-ml-qa-pairs-A\"\n",
    "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50.8k/50.8k [00:00<00:00, 22.6Mit/s]\n",
    "Uploaded file from gpt-qa-train_prepared.jsonl: file-5fYU80lXy5FQgfmfVU56k8nb\n",
    "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.2k/12.2k [00:00<00:00, 8.80Mit/s]\n",
    "Uploaded file from gpt-qa-valid_prepared.jsonl: file-99tOIqCaPbNwL90bI1K1yq23\n",
    "Created fine-tune: ft-zHk8gGvZdaBNRVheXq5fZFqt\n",
    "Streaming events until fine-tuning is complete...\n",
    "\n",
    "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
    "[2022-11-20 00:36:48] Created fine-tune: ft-zHk8gGvZdaBNRVheXq5fZFqt\n",
    "[2022-11-20 00:36:52] Fine-tune costs $0.14\n",
    "[2022-11-20 00:36:52] Fine-tune enqueued. Queue number: 0\n",
    "[2022-11-20 00:36:54] Fine-tune started\n",
    "[2022-11-20 00:37:54] Completed epoch 1/4\n",
    "[2022-11-20 00:38:06] Completed epoch 2/4\n",
    "[2022-11-20 00:38:18] Completed epoch 3/4\n",
    "[2022-11-20 00:38:30] Completed epoch 4/4\n",
    "[2022-11-20 00:38:46] Uploaded model: curie:ft-personal-2022-11-20-08-38-46\n",
    "[2022-11-20 00:38:47] Uploaded result file: file-EZy5duulRUswzYdqj6LuW76a\n",
    "[2022-11-20 00:38:47] Fine-tune succeeded\n",
    "\n",
    "Job complete! Status: succeeded ðŸŽ‰\n",
    "Try out your fine-tuned model:\n",
    "\n",
    "openai api completions.create -m curie:ft-personal-2022-11-20-08-38-46 -p <YOUR_PROMPT>\n",
    "(ml) SF-mbp:gpt-fine-tuning stephen$ -m \"davinci\" \\\n",
    "> --suffix \"gpt-ml-qa-pairs-A\"\n",
    "-bash: -m: command not found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying again \n",
    "\n",
    "$ openai api fine_tunes.create \\\n",
    "> -t gpt-qa-train_prepared.jsonl \\\n",
    "> -v gpt-qa-valid_prepared.jsonl \\\n",
    "> -m \"davinci\" \\\n",
    "> --suffix \"gpt-ml-qa-pairs-A\"\n",
    "Found potentially duplicated files with name 'gpt-qa-train_prepared.jsonl', purpose 'fine-tune' and size 50782 bytes\n",
    "file-5fYU80lXy5FQgfmfVU56k8nb\n",
    "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway:\n",
    "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50.8k/50.8k [00:00<00:00, 21.8Mit/s]\n",
    "Uploaded file from gpt-qa-train_prepared.jsonl: file-XCo6Sza9cVyfIWjPmoatpK3s\n",
    "Found potentially duplicated files with name 'gpt-qa-valid_prepared.jsonl', purpose 'fine-tune' and size 12227 bytes\n",
    "file-99tOIqCaPbNwL90bI1K1yq23\n",
    "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway:\n",
    "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.2k/12.2k [00:00<00:00, 6.49Mit/s]\n",
    "Uploaded file from gpt-qa-valid_prepared.jsonl: file-HbOaJkGRRu4hp4C8DQ4PtZ0t\n",
    "Created fine-tune: ft-xNzKl8ORDdASWIALy5WoSLcY\n",
    "Streaming events until fine-tuning is complete...\n",
    "\n",
    "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
    "[2022-11-20 00:45:39] Created fine-tune: ft-xNzKl8ORDdASWIALy5WoSLcY\n",
    "[2022-11-20 00:45:46] Fine-tune costs $1.42\n",
    "[2022-11-20 00:45:47] Fine-tune enqueued. Queue number: 0\n",
    "[2022-11-20 00:45:48] Fine-tune started\n",
    "[2022-11-20 00:47:30] Completed epoch 1/4\n",
    "[2022-11-20 00:47:50] Completed epoch 2/4\n",
    "[2022-11-20 00:48:10] Completed epoch 3/4\n",
    "[2022-11-20 00:48:30] Completed epoch 4/4\n",
    "[2022-11-20 00:49:22] Uploaded model: davinci:ft-sandbox:gpt-ml-qa-pairs-a-2022-11-20-08-49-22\n",
    "[2022-11-20 00:49:23] Uploaded result file: file-rGIPU3ndPAZXVRSBT4xhjDKy\n",
    "[2022-11-20 00:49:23] Fine-tune succeeded\n",
    "\n",
    "Job complete! Status: succeeded ðŸŽ‰\n",
    "Try out your fine-tuned model:\n",
    "\n",
    "openai api completions.create -m davinci:ft-sandbox:gpt-ml-qa-pairs-a-2022-11-20-08-49-22 -p <YOUR_PROMPT>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Test prompts --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_answer(prompt, ftm_name_, printit=False): \n",
    "\n",
    "    prompt += \"\\n\\n###\\n\\n\"\n",
    "\n",
    "    if printit:\n",
    "        print(f\"creating call from {ftm_name_} with prompt: {prompt}\")\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=ftm_name_,\n",
    "        # engine=\"text-davinci-002\", \n",
    "        prompt=prompt,\n",
    "        temperature=0.9,\n",
    "        max_tokens=500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0.6,\n",
    "        stop=[\"\\n<+++>\\n\"]\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['text']\n",
    "\n",
    "# davinci:ft-sandbox:gpt-ml-qa-pairs-b-2022-11-20-09-29-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Run a previously trained model for testing ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for testing for now \n",
    "\n",
    "# ftm_id = \"ft-xXiSGiL0RrMUpKikJw09T1up\" # this model in particular was returning results with weird formatting, maybe something with the START and END sequences \n",
    "# ftm_name = get_ftmodel_name_from_id(ftm_id)\n",
    "\n",
    "# ftm_name = \"davinci:ft-sandbox:gpt-ml-qa-pairs-a-2022-11-20-08-49-22\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Run with the current model ---      \n",
    "\n",
    "--> Loads the model again from `ftm_id`\n",
    "\n",
    "Why? Only after it has trained will it have a `name`, which is needed to send as the `model` param to the OpenAI Completion endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftm = get_ftm_from_id(ftm_id)\n",
    "ftm_name = ftm['fine_tuned_model']\n",
    "ftm_status = ftm['status']\n",
    "\n",
    "print (f\"###\\n{ftm_name} \\nstatus: {ftm_status}\\n###\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run a single test prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the difference between a neural network and a deep learning model?\" \n",
    "#ftm_name is defined after creating the ftm\n",
    "print(get_gpt_answer(prompt, ftm_name, printit=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run a battery of test prompts on the model from \"test-prompts.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save all the question, answer pairs to a csv\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('tests/test-prompts.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    with open('test-outputs/gpt-completions-to-test-prompts.csv', 'w',newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['prompt','completion'])\n",
    "        for i, line in enumerate(lines):\n",
    "            print(f'Question {i}: {line}')\n",
    "            answer = get_gpt_answer(line, ftm_name)\n",
    "            print(f'Answer {i}: {answer} \\n\\n\\n')\n",
    "            writer.writerow([line, answer])t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Previously trained example --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the openai api with a prompt and get a response\n",
    "\n",
    "ftm_name = \"davinci:ft-sandbox:gpt-ml-qa-pairs-b-2022-11-20-09-29-25\"\n",
    "\n",
    "prompt = \"What is the difference between a neural network and a deep learning model?\" \n",
    "\n",
    "print(get_gpt_answer(prompt, ftm_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Hyperparameter Exploration --\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i could generate over several hyperparameters, \n",
    "# create a function that makes the call \n",
    "# saves the output \n",
    "# gets the finetuned model id\n",
    "# and then calls the next function with the finetuned model id as an argument\n",
    "\n",
    "\n",
    "# can i create a df of openai models and then iterate through it?\n",
    "# or do i need to create a function that takes the model id as an argument?\n",
    "# or do i need to create a function that takes the model id as an argument and then calls the next function with the finetuned model id as an argument?\n",
    "\n",
    "# i think i need to create a function that takes the model id as an argument and then calls the next function with the finetuned model id as an argument\n",
    "\n",
    "# function: takes in a dataset (just training set for now for simplicity) \n",
    "# outputs a finetuned model \"return\" \n",
    "\n",
    "# HYPERPARAMETER EXPLORATION \n",
    "\n",
    "EXPLORE_HYPERPARAMS=False\n",
    "\n",
    "# create a set of various hyperparameters to iterate through\n",
    "# create a ftmodel for each one \n",
    "# save the ftmodel id to a list\n",
    "# then iterate through the list and generate responses to the test-prompts for each one\n",
    "# save the responses to a list\n",
    "# then compare the responses to the test answers\n",
    "import time \n",
    "\n",
    "# wrap this in tqdm to show progress\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "# currsuffix = banana_suffix+suffix\n",
    "currsuffix = \"curie:ft-personal-2022-11-20-08-38-46\"\n",
    "\n",
    "def create_ftm_suffix(base,**kwargs):\n",
    "    str = base + \":\" + \"_\".join([f\"{k}-{v}, \" for k,v in kwargs.items()])\n",
    "    return str\n",
    "\n",
    "def already_exists_ftm(suffix):\n",
    "    all_ft_models = openai.FineTune.list()['data']\n",
    "\n",
    "    # this checks if the current name is already in the list of ft models\n",
    "    # any( ) returns True if any element in the list is True\n",
    "    exists = any([True for i in all_ft_models if suffix in i['fine_tuned_model']])\n",
    "    print('ftmodel already exists: ', suffix)\n",
    "    return exists\n",
    " \n",
    "\n",
    "banana_file = \"gpt-qa-train-formatted_prepared.jsonl\"\n",
    "\n",
    "base_suffix=\"qa-train-iterate\"\n",
    "# create a set of various hyperparameters to iterate through\n",
    "# epochs=[1,2,3,4]\n",
    "# learning_rate_multiplier=[0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "epochs=[1,2]\n",
    "learning_rate_multiplier=[0.1, 0.05, 0.01]\n",
    "\n",
    "suffixes=['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "ftmodels=pd.DataFrame(columns=['id', 'epochs', 'learning_rate_multiplier', 'suffix'])\n",
    "\n",
    "ftmodelcompletions = pd.DataFrame(columns=['id', 'ftm_name', 'epochs', 'learning_rate_multiplier', 'suffix', 'prompt','completion'])\n",
    "\n",
    "# create a ftmodel for each one\n",
    "\n",
    "def explore_hyperparams():\n",
    "\n",
    "    for epoch in tqdm(epochs):\n",
    "    # for epoch in epochs:\n",
    "\n",
    "        for lrm in tqdm(learning_rate_multiplier):\n",
    "\n",
    "            #check if the current model already exists. if so, skip it\n",
    "            curr_suffix = create_ftm_suffix(base_suffix,lrm=lrm, epoch=epoch)\n",
    "\n",
    "            # if already_exists_ftm(curr_suffix): continue\n",
    "\n",
    "            # @TODO actually this should say: \n",
    "            # if already exists, then don't create the finetuned model, just get the id\n",
    "            # if doesn't exist then create it, and then get the id \n",
    "\n",
    "            # create a ft model with these parameters \n",
    "            ftm = file_to_finetuned_model(\n",
    "                train_file=banana_file,\n",
    "                suffix=curr_suffix,\n",
    "                n_epochs=epoch,\n",
    "                learning_rate_multiplier=lrm\n",
    "            )\n",
    "\n",
    "            ftm_id = ftm['id']\n",
    "\n",
    "            print(f\"\\n\\n======================= Initiated ftm:  ======================= \\n ftm_id: {ftm_id}. \\n Now we wait for the model to train... \\n\")\n",
    "\n",
    "            # wait for the ft model to finish training\n",
    "            current_ft_model_is_ready = await_ft_ready(ftm_id)\n",
    "            if not current_ft_model_is_ready: \n",
    "                print(f\"finetuned model timed out: {ftm_id}\")\n",
    "                continue\n",
    "\n",
    "            # the model has passed the await test, so it can be called now\n",
    "            # it's also been given a name, so it can be called by ftm_name now\n",
    "            # ftm_name = ftm['fine_tuned_model'] # the name is stored as ftm['fine_tuned_model']\n",
    "\n",
    "            ftm = openai.FineTune.retrieve(ftm_id) # need to retrieve the fresh version with its name! \n",
    "            \n",
    "            ftm_name = ftm['fine_tuned_model']\n",
    "\n",
    "            print (ftm_name, curr_suffix)\n",
    "            #also we could derive the name from the suffix! although they add a timestamp to the end of the name, which we'd want to emulate \n",
    "\n",
    "\n",
    "            print (f\"{ftm_id} finetuned model is now ready for testing. \\nIts name is: {ftm_name}\\n\")\n",
    "\n",
    "            # append this model to the df \n",
    "            ftmodels = ftmodels.append({'id': ftm_id, 'ftm_name': ftm_name, 'epochs': epoch, 'learning_rate_multiplier': lrm, 'suffix': curr_suffix}, ignore_index=True)\n",
    "\n",
    "            # now test every prompt with every ftmodel\n",
    "            with open ('test-prompts.txt') as f:\n",
    "                print(f\"starting test-prompts on finetuned model {ftm_id}\")\n",
    "                prompts = f.readlines()\n",
    "                for prompt in tqdm(prompts):\n",
    "                    # get the completion for this prompt\n",
    "                    completion = get_gpt_answer(prompt, ftm_name, printit=True)\n",
    "                    # append this completion to the df\n",
    "                    ftmodelcompletions = ftmodelcompletions.append(\n",
    "                        {'id': ftm_id, \n",
    "                        'ftm_name': ftm_name,\n",
    "                        'epochs': epoch, \n",
    "                        'learning_rate_multiplier': lrm, \n",
    "                        'suffix': curr_suffix, \n",
    "                        'prompt': prompt, \n",
    "                        'completion': completion}, \n",
    "                        ignore_index=True)\n",
    "                print('\\n\\n\\nCompleted test prompts for ftmodel: ', ftm_id)\n",
    "\n",
    "    ftmodels.to_csv('ftmodels.csv')\n",
    "    ftmodelcompletions.to_csv('ftmodelcompletions.csv')\n",
    "\n",
    "    print(ftmodels.head())\n",
    "    print(ftmodelcompletions.head())\n",
    "\n",
    "\n",
    "if EXPLORE_HYPERPARAMS: \n",
    "    explore_hyperparams()\n",
    "\n",
    "    # SUCCESS! \n",
    "    print(ftmodels.head())\n",
    "    print(ftmodelcompletions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d905c6a59c21f0f46be93fdc832728644d115a3fdfd57971d06d899b53e0576e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
