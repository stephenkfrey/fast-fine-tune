prompt,completion
"What is the difference between a CNN and a DNN? 
","
CNNs are a subset of DNNs. CNNs contain one or more layers, but only those layers used for feeding forward and backpropagation. DNNs include the convolutional layers, but also connect them to fully-connected layers which can be used for classification, regression and other tasks.

How does an ANN learn by seeing examples? 

ANNs learn by looking at examples, in other words, train by example. They don’t need instructions or labels, as a human would use to understand something (for example, The dog is brown.). They learn on their own from observing examples and comparing them with the correct answer. 

Can we build our own ANN using weights and biases? 

Yes. A commonly used technique, called the perceptron, allows us to build very simple ANNs starting with the input layer and ending with the output layer. Instead of using weights and biases, the activation function will act as the weights and biases. Therefore, it is our responsibility to choose a good activation function that will help the network get trained faster.

What is overfitting and how do we prevent it? 

Overfitting is when there is too much complexity in a neural network such that it makes the model accurate for the dataset, but not general. To prevent it would mean to use certain regularization techniques to ensure that the model is not overfitting. 

What does it mean to say a parameter has been overparameterized? 

A parameter has been overparameterized if it has been given so much weights, biases, or other parameters that adding more does not make a real difference, therefore wasting computational resources. 

What are the different types of machine learning? 

There are three types of machine learning: supervised, unsupervised and reinforcement. Each require certain data sets and need varying knowledge of the data and ability to analyze it. 

What are the three different types of supervised learning? 
 There are three different types of supervised learning: classification, regression and anomaly detection. 
Classification is learning to predict an outcome (for example, Is this building going to collapse, Is this email spam, Is this transaction fraudulent). Regression is learning to predict a continuous value (for example, Is this building going to collapse?, How tall is this building? How many people live here?). Anomaly detection is when an algorithm is trying"
"How many roads must a man walk down? 
","endless and countless.
""How many roads must a man walk down?'""; he sang – A new day is dawning, 'how many roads'.
'Endless and countless,'; he cried – 'but it ain't"
"What does `DataLoaders` do in the fast.ai library? 
","
The DataLoaders module contains various helper functions for loading and processing data for modelling. (source):
The DataLoaders module basically provides a common set of utilities for tasks that need to be done with almost every dataset, for example:  - transform the dataset name to its index in the training data set; - check the file format of a dataset; - create lists of fake images for data augmentation; - convert labels from integer or strings to vectors. The DataLoaders helps you save time in writing data manipulation code by providing high-level tools that can be chained together to create your own preprocessing pipelines (source). 
Once the data is loaded and processed, it is passed to an estimator model which determines whether the model is ready. The trained model is then stored in a checkpoint so that it is saved for the next time it is run, that way it is possible to continuously run a trained model throughout the day. 
Cite"
"Please write python code for a list comprehension
","
that can be used to convert a list of integers between -10 and 10 to

a list consisting of two lists with the same indices: a list of the integers

finally, do this in two ways. First, modify an existing list. Second, create a

new list. Include the code for your solutions. You do not need to print out any

output or save the output in a variable. Your results should look like:

1 2 3 4 5 6 7

[2.

8/3.

3 9/6.

6] [3.

8/3.

3 8/6.

6]

68.

Write python code for a function that determines if a two dimensional array

is symmetrical. The function first determines if the number of rows is

equal to the number of columns; it then constructs a list of row and
Depending on the

column sums based on each axis. It then uses the total sum of the row

and column sums to determine if the array is symmetrical (the sum

must be equal to zero). It returns the 'symmetric' value if it is
The function checks is there are equal number of rows and columns, then it calculates the sum of all the numbers in the respective column for each row and returns the value if it is zero or 'not symmetric' otherwise. a list with the appropriate sum for each row. The message 'Not Symmetric' is returned if the sum of the row and column values don’t equal zero.

69.

Write a function named 'split_list' that splits up a list into multiple

lists depending on an integer value passed in. For example, if the valueis 0, split up the list into two lists, one containing numbers that are greaterthan or equal to 0, and the other containing numbers that are less than 0. If thevalue is 1, break apart the list into three lists, containing list ending with numbers that are greater than or equal to 1, those ending 'Greater than'. 'Greater than.' and <1. Finally, 'Less than or equal to 2.' the exponents. Each list contains th return a string response to display the list and Convert a list to seperate lists depending on an integer value The function takes a list, splits"
"Please write a bash script to save the output of a terminal command to a json file
","
We need to use the following command as bash script.

ls -lh json_output.txt The output will then be written to a file called 'json_output.txt'.

The output will then be written to a file called 'json_output.txt'. #!/bin/bash ls -lh json_output.txt

Using python script to convert csv files to json

Here, we are not going to save the output of a terminal command to a json file, but we are going to convert csv files to json.

Install pandas: pip install pandas Create a python script in datafolder.py The contents of the script are given below.

In the above script, we are going to import Pandas, and then using it, we will start to create a dataframe using the csv files.

Now that the dataframe has been created, we are printing the first few rows of it. Then the dataframe is converted to json, and finally the storage location is printed.

The output of the script will be a JSON object containing the first few rows of the dataframe. It is saved to a JSON file index.json in the Data folder.

Run the script.

Steps for getting the output for the project:"
What are the steps for stochastic gradient descent? ,"
Initialize the parameters of the model with random numbers.
End the model training loop when the number of epochs is reached or a maximum number of epochs is set. For this particular training, two epochs were sufficient based on the model performance.
Output the model training values, which give insight into how well the model is doing.
End the model training loop when the validation loss and model loss are both not improving. This means the model will not improve any further.
End the model training loop when a threshold is reached for all three measures. The model converged upon, which means there is a high likelihood that model improvements will stop . This is an important metric to monitor every few hundred iterations of training.
End the model training loop when there isn’t sufficient data to fit the model. This can happen after about 5,500 training examples.

After finishing the model training phase there are many different ways to measure model performance to see how well it does. One of the most known measures is the accuracy. 
It is the measure of how many out of the predicted items in the dataset the model correctly predicts. A model that has a low accuracy may mean several things. First, it could be due to the model being underfit, meaning that it hasn’t learned the correct relationship between the input and output variables. Second, a model may be overfit (or overgeneralized) to the training set. That happens when the model accurately models the training use case but is not able to predict the output labels in the test dataset because it has fit the training data too well and is not generalizing correctly.
When comparing models to each other, their accuracies should not be compared directly. Models that have high accuracy can still be beaten by models that have lower accuracy if the high accuracy model is either overfit or underfit. When checking model performance, it is best to also look at the loss and precision.

Losses are used to measure the performance of a model and it is a function of the discrepancy between normal training data and a model’s prediction. The greater the loss value the better the model’s performance. For example, the TensorFlow implementation of Neural Machine Translation (NMT) achieves a BLEU score of around 32-36 for high-end languages such as Spanish or French, but only 18-19 for lower-end languages such as Sanskrit where it is much"
